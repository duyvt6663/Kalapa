{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import html\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import requests\n",
    "import math\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(texts, dest=\"en\", batch_size=16, delay_per_batch=2):\n",
    "    translator = Translator()\n",
    "    is_str = False\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "        is_str = True\n",
    "\n",
    "    results = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i : i + batch_size]\n",
    "        tries = 5\n",
    "        while tries > 0:\n",
    "            try:\n",
    "                results.extend(translator.translate(batch, dest=dest))\n",
    "                time.sleep(random.randint(0, delay_per_batch))\n",
    "                break\n",
    "            except Exception as e:\n",
    "                tries -= 1\n",
    "                print(e)\n",
    "                print(f\"Retrying batch {i//batch_size}/{math.ceil(len(texts)/batch_size)}\")\n",
    "                time.sleep(random.randint(0, delay_per_batch))\n",
    "\n",
    "    results = [html.unescape(r.text) for r in results]\n",
    "    if is_str:\n",
    "        return results[0]\n",
    "    else:\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Breast - Breast\": \"Vú - Nhũ\",\n",
      "    \"Pediatrics - Newborn\": \"Nhi - Sơ sinh\",\n",
      "    \"IVF Reproductive Support\": \"Hỗ trợ sinh sản IVF\",\n",
      "    \"Oncology\": \"Ung bướu\",\n",
      "    \"Psychological\": \"Tâm lý\",\n",
      "    \"Urology\": \"Tiết niệu\",\n",
      "    \"Musculoskeletal\": \"Cơ xương khớp\",\n",
      "    \"Endocrine\": \"Nội tiết\",\n",
      "    \"Heart vascular\": \"Tim mạch\",\n",
      "    \"Eye\": \"Mắt\",\n",
      "    \"COVID-19\": \"COVID-19\",\n",
      "    \"Dermatology\": \"Da liễu\",\n",
      "    \"Gastrointestinal - Hepatobiliary\": \"Tiêu hóa - Gan mật\",\n",
      "    \"Infectious\": \"Truyền nhiễm\",\n",
      "    \"Imaging\": \"Chẩn đoán hình ảnh\",\n",
      "    \"General health\": \"Sức khỏe tổng quát\",\n",
      "    \"Obstetrics - Gynecology \": \"Sản - Phụ khoa\",\n",
      "    \"Neurological\": \"Thần kinh\",\n",
      "    \"Respiratory\": \"Hô hấp\",\n",
      "    \"Ear, nose and throat\": \"Tai mũi họng\",\n",
      "    \"null\": null,\n",
      "    \"Testing\": \"Xét nghiệm\",\n",
      "    \"Andrology\": \"Nam Học\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "all_categories = ['Vú - Nhũ', 'Nhi - Sơ sinh', 'Hỗ trợ sinh sản IVF', 'Ung bướu', 'Tâm lý', 'Tiết niệu', 'Cơ xương khớp', 'Nội tiết', 'Tim mạch', 'Mắt', 'COVID-19', 'Da liễu', 'Tiêu hóa - Gan mật', 'Truyền nhiễm', 'Chẩn đoán hình ảnh', 'Sức khỏe tổng quát', 'Sản - Phụ khoa', 'Thần kinh', 'Hô hấp', 'Tai mũi họng', None, 'Xét nghiệm', 'Nam Học']\n",
    "all_en_categories = ['Breast - Breast', 'Pediatrics - Newborn', 'IVF Reproductive Support', 'Oncology', 'Psychological', 'Urology', 'Musculoskeletal', 'Endocrine', 'Heart vascular', 'Eye', 'COVID-19', 'Dermatology', 'Gastrointestinal - Hepatobiliary', 'Infectious', 'Imaging', 'General health', 'Obstetrics - Gynecology ', 'Neurological', 'Respiratory', 'Ear, nose and throat', None, 'Testing', 'Andrology']\n",
    "assert len(all_categories) == len(all_en_categories)\n",
    "\n",
    "en_category_to_vi_category = dict(zip(all_en_categories, all_categories))\n",
    "vi_category_to_en_category = dict(zip(all_categories, all_en_categories))\n",
    "\n",
    "print(json.dumps(en_category_to_vi_category, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"../datasets\"\n",
    "kalapa_dataset_dir = os.path.join(dataset_dir, \"KALAPA_ByteBattles_2023_MEDICAL_Set1\")\n",
    "processed_save_dir = os.path.join(kalapa_dataset_dir, \"processed\")\n",
    "translated_save_dir = os.path.join(kalapa_dataset_dir, \"translated\")\n",
    "\n",
    "os.makedirs(translated_save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_document(document: dict):\n",
    "    title = document[\"title\"]\n",
    "    abstract = document[\"abstract\"]\n",
    "    subsections = document[\"subsections\"]\n",
    "    \n",
    "    translated_title = translate_text(title)\n",
    "    translated_abstract = translate_text(abstract)\n",
    "    translated_subsections = []\n",
    "    \n",
    "    for subsection in subsections:\n",
    "        subsection_name = subsection[\"subsection_name\"]\n",
    "        subsection_content = subsection[\"subsection_content\"]\n",
    "        \n",
    "        translated_subsection_name, translated_subsection_content = translate_text([subsection_name, subsection_content])\n",
    "        subsection_string = translated_subsection_name + \"\\n\" + translated_subsection_content\n",
    "        \n",
    "        translated_subsection = {\n",
    "            \"subsection_name\": translated_subsection_name,\n",
    "            \"subsection_content\": translated_subsection_content,\n",
    "            \"subsection_string\": subsection_string\n",
    "        }\n",
    "        translated_subsections.append(translated_subsection)\n",
    "    \n",
    "    translated_content = [\n",
    "        translated_title,\n",
    "        translated_abstract,\n",
    "        *[subsection[\"subsection_string\"] for subsection in translated_subsections]\n",
    "    ]\n",
    "    translated_content = \"\\n\\n\".join(translated_content)\n",
    "    \n",
    "    return {\n",
    "        \"title\": translated_title,\n",
    "        \"category\": vi_category_to_en_category[document[\"category\"]],\n",
    "        \"link\": document[\"link\"],\n",
    "        \"abstract\": translated_abstract,\n",
    "        \"content\": translated_content,\n",
    "        \"subsections\": translated_subsections\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "465b8e3a59494524821b5939f35d38ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing documents:   0%|          | 0/603 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_names = sorted(os.listdir(processed_save_dir))\n",
    "error_indices = []\n",
    "for i in tqdm(range(0, len(document_names)), desc=\"Processing documents\"):\n",
    "    try:\n",
    "        document_name = document_names[i]\n",
    "        document_path = os.path.join(processed_save_dir, document_name)\n",
    "        with open(document_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            document = json.load(f)\n",
    "        translated_document = translate_document(document)\n",
    "        translated_document[\"name\"] = document_name\n",
    "\n",
    "        translated_save_path = os.path.join(translated_save_dir, document_name + \".json\")\n",
    "        with open(translated_save_path, \"w\") as f:\n",
    "            json.dump(translated_document, f, indent=4, ensure_ascii=False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Error at index {i} with document name {document_name}\")\n",
    "        error_indices.append(i)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
