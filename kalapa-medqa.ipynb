{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"5xS5XETkBsBE"},"source":["## Install libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T15:43:53.400974Z","iopub.status.busy":"2023-10-25T15:43:53.400662Z","iopub.status.idle":"2023-10-25T15:45:43.906694Z","shell.execute_reply":"2023-10-25T15:45:43.905270Z","shell.execute_reply.started":"2023-10-25T15:43:53.400946Z"},"id":"Q8GKP70ofPsY","outputId":"74e1fb74-9c8f-438f-caf5-13fb5b9c1639","trusted":true},"outputs":[],"source":["# Transformers installation\n","# !pip install evaluate -qq\n","!pip install -qq accelerate==0.21.0\n","!pip install git+https://github.com/huggingface/peft -qq\n","# !pip install -qq transformers[torch]\n","!pip install -qq wandb\n","# !pip install -qq datasets evaluate accelerate git+https://github.com/huggingface/transformers.git\n","!pip install -qq datasets evaluate git+https://github.com/huggingface/transformers.git\n","!pip install bitsandbytes"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T15:45:43.909288Z","iopub.status.busy":"2023-10-25T15:45:43.908934Z","iopub.status.idle":"2023-10-25T15:45:48.455294Z","shell.execute_reply":"2023-10-25T15:45:48.454144Z","shell.execute_reply.started":"2023-10-25T15:45:43.909252Z"},"trusted":true},"outputs":[],"source":["!wandb login eb9e407fb23283fbaed6da50d7b53f71db7b4576\n","%env WANDB_PROJECT=vimmrc"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T15:45:48.457319Z","iopub.status.busy":"2023-10-25T15:45:48.456902Z","iopub.status.idle":"2023-10-25T15:45:48.791028Z","shell.execute_reply":"2023-10-25T15:45:48.790064Z","shell.execute_reply.started":"2023-10-25T15:45:48.457274Z"},"id":"OQBE94xtfPsc","outputId":"a738bd0b-d719-476a-aade-579d9782eec2","trusted":true},"outputs":[],"source":["from huggingface_hub import login\n","\n","login(token=\"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\", add_to_git_credential=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"fM1Wau4Vfrd3"},"source":["## Import libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T15:45:48.793740Z","iopub.status.busy":"2023-10-25T15:45:48.793430Z","iopub.status.idle":"2023-10-25T15:46:03.416411Z","shell.execute_reply":"2023-10-25T15:46:03.415404Z","shell.execute_reply.started":"2023-10-25T15:45:48.793709Z"},"id":"-ghizYd9gh9m","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/aivn2023/workspace/miniconda3/envs/kalapa/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import os\n","import math\n","import warnings\n","import unicodedata\n","from typing import Sequence\n","import torch\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoConfig\n","from datasets import load_dataset\n","from transformers import DataCollatorWithPadding\n","from dataclasses import dataclass, field\n","\n","from transformers import pipeline\n","import datasets \n","datasets.disable_progress_bar()\n","\n","warnings.filterwarnings(\"ignore\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IENMRrKRfuIV"},"source":["## Hyperparameters"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T15:46:04.130586Z","iopub.status.busy":"2023-10-25T15:46:04.130320Z","iopub.status.idle":"2023-10-25T15:46:04.135250Z","shell.execute_reply":"2023-10-25T15:46:04.134258Z","shell.execute_reply.started":"2023-10-25T15:46:04.130561Z"},"id":"IA-0-kvdKkII","trusted":true},"outputs":[],"source":["id2label = {0: \"false\", 1: \"true\"}\n","label2id = {\"false\": 0, \"true\": 1}"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T15:46:04.136791Z","iopub.status.busy":"2023-10-25T15:46:04.136511Z","iopub.status.idle":"2023-10-25T15:46:04.152154Z","shell.execute_reply":"2023-10-25T15:46:04.151260Z","shell.execute_reply.started":"2023-10-25T15:46:04.136767Z"},"id":"LPmrPTSYfwhG","outputId":"32e26ed6-522a-4a3d-b42c-5b801319713d","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["do_train: True\n","do_eval: True\n","fp16: True\n","per_device_train_batch_size: 4\n","per_device_eval_batch_size: 4\n","optim: adamw_hf\n","learning_rate: 5e-05\n","weight_decay: 0.1\n","gradient_accumulation_steps: 8\n","warmup_ratio: 0.18\n","max_steps: 500\n","save_total_limit: 7\n","evaluation_strategy: steps\n","eval_steps: 50\n","output_dir: output/\n","save_strategy: steps\n","save_steps: 50\n","seed: 42\n","push_to_hub: True\n","hub_model_id: vietcuna-3b_1024\n","hub_strategy: all_checkpoints\n","load_best_model_at_end: True\n","logging_first_step: True\n","logging_steps: 50\n","report_to: wandb\n","run_name: vietcuna-3b_1024\n","data_seed: 42\n"]}],"source":["# https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments\n","ctx_length = 1024\n","SESSION_NAME = f\"vietcuna-3b_{ctx_length}\"\n","# SESSION_NAME = f\"hoa-1b4_{ctx_length}\"\n","# SESSION_NAME = f\"ura-llama_{ctx_length}\"\n","CONFIG = {\n","    # work 2 do\n","    \"do_train\": True,\n","    \"do_eval\": True,\n","\n","    # model hyperparameters\n","    \"model_name_or_path\": \"vietcuna-3b-v2/kalapa-vietcuna-3b/\",\n","    # \"model_name_or_path\": \"kalapa-ura-llama\",\n","    \"fp16\": True if torch.cuda.is_available() else False,\n","    # \"torch_compile\": True,\n","\n","    # training hyperparameters\n","    \"per_device_train_batch_size\": 4,\n","    \"per_device_eval_batch_size\": 4,\n","    \"optim\": \"adamw_hf\",\n","    \"triton\": True,\n","    \"learning_rate\": 5e-5,\n","    \"weight_decay\": 0.1,\n","    \"gradient_accumulation_steps\": 8,\n","    \"warmup_ratio\": 0.18,\n","    \"max_steps\": 500,\n","    # \"num_train_epochs\": 1,\n","    \"save_total_limit\": 7,\n","\n","    # dataset\n","    \"dataset_name\": \"train_kalapa\",\n","    \"dataset_name_config\": \"all\",\n","    \"text_column_name\": \"text\",\n","    \"block_size\": 256,\n","    \"max_length\": 256,\n","\n","    # eval hyperparameters\n","    \"evaluation_strategy\": \"steps\",\n","    \"eval_steps\": 50,\n","\n","    # directories\n","    \"output_dir\": \"output/\",\n","    \"save_strategy\": \"steps\",\n","    \"save_steps\": 50,\n","\n","    # other parameters and hub\n","    \"seed\": 42,\n","    \"push_to_hub\": True,\n","    \"hub_model_id\" : SESSION_NAME,\n","    \"hub_strategy\": \"all_checkpoints\",\n","\n","    # load best model at end for inference\n","    \"load_best_model_at_end\": True,\n","\n","    # logging\n","    \"logging_first_step\": True,\n","    \"logging_steps\": 50,\n","    \"report_to\": \"wandb\",\n","    \"run_name\": SESSION_NAME,\n","\n","    # random seed\n","    \"seed\": 42,\n","    \"data_seed\": 42,\n","}\n","\n","# keep valid arguments\n","valid_args = {\n","    k: v for k, v in CONFIG.items() if k in TrainingArguments.__init__.__code__.co_varnames\n","}\n","\n","training_args = TrainingArguments(\n","    **valid_args\n",")\n","\n","for key, value in valid_args.items():\n","    print(f\"{key}: {value}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"pFc6xRmBgCd_"},"source":["## Loading Model and Tokenizer"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T15:46:04.155971Z","iopub.status.busy":"2023-10-25T15:46:04.155670Z","iopub.status.idle":"2023-10-25T15:46:04.488631Z","shell.execute_reply":"2023-10-25T15:46:04.487633Z","shell.execute_reply.started":"2023-10-25T15:46:04.155946Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","import gc\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["del model"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T15:46:04.490276Z","iopub.status.busy":"2023-10-25T15:46:04.489931Z","iopub.status.idle":"2023-10-25T15:46:42.676161Z","shell.execute_reply":"2023-10-25T15:46:42.675356Z","shell.execute_reply.started":"2023-10-25T15:46:04.490240Z"},"id":"9Bjv-QXugEJa","outputId":"559d130b-9db6-4644-94b7-8a2d7eae4763","trusted":true},"outputs":[],"source":["from peft import get_peft_config, get_peft_model, LoraConfig, TaskType, prepare_model_for_int8_training, PeftModel\n","\n","model_config = AutoConfig.from_pretrained(\n","    CONFIG['model_name_or_path'],\n","    num_labels=2, \n","    id2label=id2label,\n","    label2id=label2id,\n","    summary_type=\"last\",\n",")\n","\n","model_config.max_position_embeddings = 4096\n","model_config.max_length = 4096\n","model_config.num_labels = 2\n","\n","tokenizer = AutoTokenizer.from_pretrained(\n","    CONFIG['model_name_or_path'],\n","    config=model_config\n",")\n","# tokenizer.sep_token = '[SEP]'\n","# tokenizer.sep_token = tokenizer.bos_token\n","tokenizer.sep_token = \"\\n\\n\"\n","\n","# peft_config = LoraConfig(\n","#     task_type=TaskType.SEQ_CLS, \n","#     # inference_mode=False, \n","#     # target_modules = ['query_key_value']\n","#     r=16, lora_alpha=32, \n","#     lora_dropout=0.05\n","# )\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    CONFIG['model_name_or_path'],\n","    config=model_config,\n","#     low_cpu_mem_usage=True,  # try to limit RAM\n","#     offload_state_dict=True,  # offload onto disk if needed\n","#     offload_folder=\"offload\",  # offload model to `offload/`\n","    load_in_8bit=True\n",")\n","# model = prepare_model_for_int8_training(model)\n","# model = get_peft_model(model, peft_config)\n","adapters_name = 'duyvt6663/vietcuna-3b_1024'\n","adapters_name = 'output/checkpoint-400'\n","model = PeftModel.from_pretrained(model, adapters_name)\n","# model = model.merge_and_unload()\n","\n","# model.print_trainable_parameters()\n","model = model.to(device=\"cuda\")"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T15:46:42.677825Z","iopub.status.busy":"2023-10-25T15:46:42.677464Z","iopub.status.idle":"2023-10-25T15:46:42.688659Z","shell.execute_reply":"2023-10-25T15:46:42.687751Z","shell.execute_reply.started":"2023-10-25T15:46:42.677791Z"},"trusted":true},"outputs":[{"data":{"text/plain":["PeftModelForSequenceClassification(\n","  (base_model): LoraModel(\n","    (model): BloomForSequenceClassification(\n","      (transformer): BloomModel(\n","        (word_embeddings): Embedding(250880, 2560)\n","        (word_embeddings_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n","        (h): ModuleList(\n","          (0-29): 30 x BloomBlock(\n","            (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n","            (self_attention): BloomAttention(\n","              (query_key_value): Linear8bitLt(\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=16, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=16, out_features=7680, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (base_layer): Linear8bitLt(in_features=2560, out_features=7680, bias=True)\n","              )\n","              (dense): Linear8bitLt(in_features=2560, out_features=2560, bias=True)\n","              (attention_dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (post_attention_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n","            (mlp): BloomMLP(\n","              (dense_h_to_4h): Linear8bitLt(in_features=2560, out_features=10240, bias=True)\n","              (gelu_impl): BloomGelu()\n","              (dense_4h_to_h): Linear8bitLt(in_features=10240, out_features=2560, bias=True)\n","            )\n","          )\n","        )\n","        (ln_f): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (score): ModulesToSaveWrapper(\n","        (original_module): Linear(in_features=2560, out_features=2, bias=False)\n","        (modules_to_save): ModuleDict(\n","          (default): Linear(in_features=2560, out_features=2, bias=False)\n","        )\n","      )\n","    )\n","  )\n",")"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# model = model.to(device=\"cuda\")\n","model.eval()"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 5,120 || all params: 3,007,482,880 || trainable%: 0.00017024203309845608\n"]}],"source":["model.print_trainable_parameters()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"G9ewN_XdfPsc"},"source":["## Load dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","df = pd.read_csv('level_1_unroll.csv')\n","# df = pd.read_csv(train_paths[0])\n","# df = df.drop(['Unnamed: 0'], axis=1)\n","\n","# df.to_csv('formated_public_test.csv', index=False)\n","df.head()\n","df = df.drop(['Unnamed: 0', 'level', 'instruction'], axis=1)\n","df.to_csv('level_1_public_test.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","data_path = 'mcqa-data/MedMCQA/'\n","# data_path = 'synthetic-gpt4-data'\n","train_paths = [os.path.join(data_path, p) for p in os.listdir(data_path)]\n","newpaths = []\n","for path in train_paths:\n","    # if all(p not in path for p in ['1.', '2.']):\n","    #     continue\n","    df = pd.read_csv(path)\n","    # df = df.dropna()\n","    # df = df.drop(['Unnamed: 0'], axis=1)\n","    print(len(df))\n","    df.to_csv(path, index=False)\n","    newpaths.append(path)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["newpaths"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T15:46:42.689958Z","iopub.status.busy":"2023-10-25T15:46:42.689668Z","iopub.status.idle":"2023-10-25T15:46:43.384063Z","shell.execute_reply":"2023-10-25T15:46:43.383134Z","shell.execute_reply.started":"2023-10-25T15:46:42.689935Z"},"id":"AxHvWZOdfPsc","outputId":"7d9cac44-89fc-4df8-94cd-fae2a2ab5026","trusted":true},"outputs":[],"source":["dataset = load_dataset(\"csv\", data_files = {'train': newpaths, \n","                                            'validate': 'level_1_public_test.csv'})\n","print(dataset)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"NvEHWVQ6fPsd"},"source":["## Preprocess"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T15:46:43.391430Z","iopub.status.busy":"2023-10-25T15:46:43.391147Z","iopub.status.idle":"2023-10-25T15:46:43.401555Z","shell.execute_reply":"2023-10-25T15:46:43.400706Z","shell.execute_reply.started":"2023-10-25T15:46:43.391406Z"},"trusted":true},"outputs":[],"source":["# def create_input_text(examples):\n","#     questions = examples['question']\n","#     answers = examples['option']\n","#     contexts = examples['context']\n","    \n","#     new_examples = { \"label\": examples['label'], \"text\": [] }\n","#     for q, a, c in zip(questions, answers, contexts):\n","# #         text = q + tokenizer.sep_token + a + tokenizer.sep_token + c\n","#         text = \"Dựa vào ngữ cảnh được cung cấp, cho biết rằng câu trả lời dưới đây có phải là đáp án chính xác cho câu hỏi hay không.\" + tokenizer.sep_token + \"Câu hỏi: \" + q + tokenizer.sep_token + \"Câu trả lời: \" + a + tokenizer.sep_token + \"Ngữ cảnh: \" + c\n","#         new_examples['text'].append(text)\n","#     return new_examples\n","\n","def create_input_text_2(examples):\n","    questions = examples['question']\n","    answers = examples['option']\n","    contexts = examples['context']\n","    \n","    new_examples = { \"label\": examples['label'], \"text\": [] }\n","    for q, a, c in zip(questions, answers, contexts):\n","        try:\n","#         text = q + tokenizer.sep_token + a + tokenizer.sep_token + c\n","            text = \"Dựa vào ngữ cảnh được cung cấp, cho biết rằng câu trả lời dưới đây có phải là đáp án chính xác cho câu hỏi hay không.\" + tokenizer.sep_token + \"Ngữ cảnh: \" + c + tokenizer.sep_token +  \"Câu hỏi: \" + q + tokenizer.sep_token + \"Câu trả lời: \" + a\n","            new_examples['text'].append(text)\n","        except Exception as e:\n","            # print(e)\n","            q = '*' if q is None else q\n","            a = '*' if a is None else a\n","            print(q + '$$$' + a + '$$$' + c + '\\n')\n","            break\n","    return new_examples\n","\n","def create_input_text_3(examples):\n","    questions = examples['question']\n","    answers = examples['option']\n","    contexts = examples['context']\n","    \n","    new_examples = { \"label\": examples['label'], \"text\": [] }\n","    for q, a, c in zip(questions, answers, contexts):\n","        try:\n","#         text = q + tokenizer.sep_token + a + tokenizer.sep_token + c\n","            text = \"[INST] <<SYS>> Dựa vào ngữ cảnh được cung cấp, cho biết rằng câu trả lời dưới đây có phải là đáp án chính xác cho câu hỏi hay không. <<SYS>>\" + tokenizer.sep_token + \"Ngữ cảnh: \" + c + tokenizer.sep_token +  \"Câu hỏi: \" + q + tokenizer.sep_token + \"Câu trả lời: \" + a + ' [/INST]'\n","            new_examples['text'].append(text)\n","        except Exception as e:\n","            # print(e)\n","            q = '*' if q is None else q\n","            a = '*' if a is None else a\n","            print(q + '$$$' + a + '$$$' + c + '\\n')\n","            break\n","    return new_examples"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T15:46:43.403315Z","iopub.status.busy":"2023-10-25T15:46:43.402766Z","iopub.status.idle":"2023-10-25T15:46:44.982233Z","shell.execute_reply":"2023-10-25T15:46:44.981137Z","shell.execute_reply.started":"2023-10-25T15:46:43.403280Z"},"id":"d2Hi_7XfIYXs","trusted":true},"outputs":[],"source":["dataset = dataset.map(\n","    create_input_text_2,\n","    batched=True,\n","    num_proc=os.cpu_count() * 2,\n","    remove_columns=dataset['train'].column_names,\n",")\n","dataset['validate'][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T15:46:44.983963Z","iopub.status.busy":"2023-10-25T15:46:44.983645Z","iopub.status.idle":"2023-10-25T15:46:44.989495Z","shell.execute_reply":"2023-10-25T15:46:44.988121Z","shell.execute_reply.started":"2023-10-25T15:46:44.983931Z"},"id":"7uxQpm3BfPse","trusted":true},"outputs":[],"source":["def preprocess_function(examples):\n","    return tokenizer.batch_encode_plus(examples[\"text\"], truncation=True, add_special_tokens=True, max_length=2048)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T15:46:44.991181Z","iopub.status.busy":"2023-10-25T15:46:44.990819Z","iopub.status.idle":"2023-10-25T15:46:48.131345Z","shell.execute_reply":"2023-10-25T15:46:48.130296Z","shell.execute_reply.started":"2023-10-25T15:46:44.991148Z"},"id":"sbJnf4AqfPse","outputId":"06b006b2-a901-48d5-fc46-7c8862c84ff8","trusted":true},"outputs":[],"source":["data = dataset.map(\n","    preprocess_function,\n","    batched=True,\n","    num_proc=os.cpu_count() * 2,\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"tWP0hHyTAuDl"},"source":["## Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T15:46:48.169308Z","iopub.status.busy":"2023-10-25T15:46:48.168963Z","iopub.status.idle":"2023-10-25T15:46:49.069878Z","shell.execute_reply":"2023-10-25T15:46:49.068940Z","shell.execute_reply.started":"2023-10-25T15:46:48.169274Z"},"id":"rXmBYLpdAwkQ","trusted":true},"outputs":[],"source":["import evaluate\n","import numpy as np\n","\n","accuracy = evaluate.load(\"accuracy\")\n","\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    predictions = np.argmax(predictions, axis=1)\n","    return accuracy.compute(predictions=predictions, references=labels)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"wD6CDD9NfPsf"},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T15:46:49.071432Z","iopub.status.busy":"2023-10-25T15:46:49.071136Z","iopub.status.idle":"2023-10-25T15:46:50.106486Z","shell.execute_reply":"2023-10-25T15:46:50.105188Z","shell.execute_reply.started":"2023-10-25T15:46:49.071406Z"},"trusted":true},"outputs":[],"source":["!export CUDA_LAUNCH_BLOCKING=1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-25T15:46:50.108745Z","iopub.status.busy":"2023-10-25T15:46:50.108330Z"},"id":"DKdLsm_PfPsf","outputId":"3adc249d-5059-4256-8667-31a8287d9bdb","trusted":true},"outputs":[],"source":["import transformers\n","from transformers import DataCollatorWithPadding, Trainer\n","from torch import nn\n","\n","# class CustomTrainer(Trainer):\n","#     def compute_loss(self, model, inputs, return_outputs=False):\n","#         labels = inputs.pop(\"labels\")\n","#         # forward pass\n","#         outputs = model(**inputs)\n","#         logits = outputs.get(\"logits\")\n","#         # compute custom loss (suppose one has 2 labels with different weights)\n","#         loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([0.6, 0.4], device=model.device))\n","#         loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n","#         return (loss, outputs) if return_outputs else loss\n","\n","trainer = Trainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    args=training_args,\n","    train_dataset=data[\"train\"],\n","    eval_dataset=data[\"validate\"],\n","    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n","    compute_metrics=compute_metrics,\n",")\n","\n","with torch.autocast(\"cuda\"): \n","    trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HmOwh1xmfPsf","trusted":true},"outputs":[],"source":["trainer.push_to_hub()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import gc\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
